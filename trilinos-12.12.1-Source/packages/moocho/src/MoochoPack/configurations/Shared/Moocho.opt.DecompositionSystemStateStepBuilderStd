*** Moocho.opt.DecompositionSystemStateStepBuilderStd 

**********************************************************************************
*** All of these options can be used with any NLPAlgoConfig
*** subclass that uses the standard DecompositionSystemStateStepBuilderStd
*** class.
***
*** This file will be maintained and will include every option that
*** users can set.  Most of these options the user will want to leave
*** alone but they are there in any case.
***

***********************************************************
*** Options for IterationPack::Algorithm
***
*** These are options that are used by every IterationPack::Algorithm
*** object that gets created and used.
***
options_group IterationPack_Algorithm {

*   interrupt_file_name = "";             *** Does not check for interrupt file [default]
*   interrupt_file_name = "interrupt.in"; *** checks for this file in current directory
    *** This specifies a file name that is looked for at the end of every
    *** step in a running algorithm.  If this file exists, it is read for
    *** algorithm termination criteria (see the class IterationPack::Algorithm
    *** and the option interrupt_file_name).  Using a file to interrupt an running
    *** algorithm allows the algorithm to be gracefully terminated when run in batch
    *** mode or when access to STDOUT or STDIN is not possible.

}

*****************************************************************
*** Options specific for the shared rSQP algorithm builder
*** class DecompositionSystemStateStepBuilderStd.
***
options_group DecompositionSystemStateStepBuilderStd {

*** Variable Reduction range/null space decomposition

*    null_space_matrix = AUTO;         *** Let the solver decide [default]
*    null_space_matrix = EXPLICIT;     *** Compute and store D = -inv(C)*N explicitly
*    null_space_matrix = IMPLICIT;     *** Perform operations implicitly with C, N (requires adjoints)
     *** This option is used to determine the type of implementation to use for
     *** the variable reduction null space matrix Z = [ -inv(C)*N; I ].
     ***    AUTO     : Let the algorithm decide.  The algorithm will take into
     ***               account the number of degrees of freedom in the problem
     ***               (n-r), the number of active inequality constraints and
     ***               other issues when deciding what implementation to use within
     ***               each iteration.  Warning!  These automatic tests are only
     ***               affective when a direct solver for C is used.
     ***    EXPLICIT : The matrix D = -inv(C)*N is computed and formed explicitly and is used
     ***               to form Z = [ D; I ].
     ***    IMPLICIT : The matrix D = -inv(C)*N is not formed explicitly but is
     ***               instead used implicitly in matrix-vector and other
     ***               related operations.

*    range_space_matrix = AUTO;        *** Let the algorithm decide dynamically [default]
*    range_space_matrix = COORDINATE;  *** Y = [ I; 0 ] (Cheaper computationally)
*    range_space_matrix = ORTHOGONAL;  *** Y = [ I; -N'*inv(C') ] (more stable)
     *** This option is used to determine the selection of the range space matrix Y.
     ***    AUTO      : Let the algorithm decide.  The algorithm will take into
     ***                account the number of degrees of freedom in the problem
     ***                (n-r) and other issues when deciding what representation to use.
     ***                Warning!  These automatic tests are only affective when a direct
     ***                solver for C is used.
     ***   COORDINATE : Use the coordinate decomposition Y = [ I; 0 ]
     ***   ORTHOGONAL : Use the orthogonal decomposition Y = [ I; N'*inv(C') ].
     ***                Warning!  For general NLPs this option costs approximately
     ***                O((n-r)^2*r) dense flops per rSQP iteration and will dominate
     ***                the runtime for large (n-r).  In addition, this option
     ***                assumes that you will be using null_space_matrix=EXPLICIT.

*** Reduced Hessian Approximations

*    max_dof_quasi_newton_dense = -1; *** [default]
     *** [quasi_newton == AUTO] (+-int)  This option is used to
     *** determine when the algorithm will switch from quasi_newton=BFGS
     *** to quasi_newton=LBFGS and from range_space_matrix=ORTHOGONAL
     *** to range_space_matrix=COORDINATE.
     *** Example values:
     ***  -1 : (< 0) Let the solver decide dynamically [default]
     ***   0 : Always use limited memory LBFGS and COORDINATE.
     *** 500 : Use LBFGS when n-r >= 500 and dense BFGS when n-m < 500
     ***       Use COORDINATE when (n-m)*r >= 500 and ORTHOGONAL when
     ***       (n-r)*r <= 500.
     *** 1e10: Always use the dense BFGS and the orthogonal decomposition.

}

***************************************************************
*** Options group for CalcFiniteDiffProd class
***
*** These options control how finite differences are computed
*** for testing and for other purposes.
***
options_group CalcFiniteDiffProd {

*    fd_method_order = FD_ORDER_ONE;          *** Use O(eps) one sided finite differences
*    fd_method_order = FD_ORDER_TWO;          *** Use O(eps^2) one sided finite differences
*    fd_method_order = FD_ORDER_TWO_CENTRAL;  *** Use O(eps^2) two sided central finite differences
*    fd_method_order = FD_ORDER_TWO_AUTO;     *** Uses FD_ORDER_TWO_CENTRAL or FD_ORDER_TWO
*    fd_method_order = FD_ORDER_FOUR;         *** Use O(eps^4) one sided finite differences
*    fd_method_order = FD_ORDER_FOUR_CENTRAL; *** Use O(eps^4) two sided central finite differences
*    fd_method_order = FD_ORDER_FOUR_AUTO;    *** [default] Use FD_ORDER_FOUR_CENTRAL or FD_ORDER_FOUR
     *** Selects the finite differencing method to use.  Several different
     *** methods of different orders are available.  For more accuracy use a higher order
     *** method, for faster execution time use a lower order method.

*    fd_step_select = FD_STEP_ABSOLUTE; *** [default] Use absolute step size fd_step_size
*    fd_step_select = FD_STEP_RELATIVE; *** Use relative step size fd_step_size * ||x||inf
     *** Determines how the actual finite difference step size that is used is selected.
     ***    FD_STEP_ABSOLUTE : The actual step size used is taken from fd_step_size or
     ***                       is determined by the implementation if fd_step_size < 0.0.
     ***                       Taking an absolute step size can result in inaccurate gradients
     ***                       for  badly scaled NLPs.
     ***    FD_STEP_RELATIVE : The actual step size used is taken from fd_step_size or
     ***                       is determined by the implementation if fd_step_size < 0.0
     ***                       and then multiplied by ||x||inf.  Taking a relative step
     ***                       will not always result in accurate gradients and the user
     ***                       may have to play with fd_step_size some.

*    fd_step_size = -1.0; *** [default] Let the implementation decide
     *** Determines what finite difference step size to use.  If fd_step_select=FD_STEP_ABSOLUTE
     *** then this is the absolute step size that is used.  If fd_step_select=FD_STEP_RELATIVE
     *** the actual step size used in fd_step_size * ||x||inf.
     *** Some common values are:
     ***   < 0.0   : let the implementation decide.
     ***   1e-8    : Optimal step size for FD_ORDER_ONE for IEEE double and perfect scaling?
     ***   1e-5    : Optimal step size for FD_ORDER_TWOx for IEEE double and perfect scaling?
     ***   1e-3    : Optimal step size for FD_ORDER_FOURx for IEEE double and perfect scaling?

*    fd_step_size_min = -1.0; *** [default] Let the implementation decide.
     *** Determines the minimum step size that will be taken to compute the finite differences.
     *** This option is used to forbid the computation of a finite difference with a very small
     *** step size as required by the variable bounds.  Computing finite difference derivatives
     *** for such small step sizes generally result in a lot of roundoff error.  If
     *** fd_step_size_min < 0.0, then the implementation will pick a default value that is
     *** smaller than the default value for fd_step_size.

*    fd_step_size_f = -1.0; *** [default] Let the implementation decide
     *** Determines what finite difference step size to use for the objective function
     *** f(x).  If fd_step_size_f < 0.0, then the selected value for fd_step_size will be
     *** used (see the options fd_step_size and fd_step_select).  This option allows
     *** fine-tuning of the finite difference computations.

*    fd_step_size_c = -1.0; *** [default] Let the implementation decide
     *** Determines what finite difference step size to use for the equality constraints
     *** c(x).  If fd_step_size_c < 0.0, then the selected value for fd_step_size will be
     *** used (see the options fd_step_size and fd_step_select).  This option allows
     *** fine-tuning of the finite difference computations.

*    fd_step_size_h = -1.0; *** [default] Let the implementation decide
     *** Determines what finite difference step size to use for the inequality constraints
     *** h(x).  If fd_step_size_h < 0.0, then the selected value for fd_step_size will be
     *** used (see the options fd_step_size and fd_step_select).  This option allows
     *** fine-tuning of the finite difference computations.

}

***************************************************************
*** Options for EvalNewPoint for NLPFirstOrder.
*** See options_group NLPFirstDerivTester
***
options_group EvalNewPointStd {

*    fd_deriv_testing = FD_DEFAULT; *** [default] Test if check_results==true (see above)
*    fd_deriv_testing = FD_TEST;    *** Always test
*    fd_deriv_testing = FD_NO_TEST; *** never test
     *** Determines if the derivatives of the NLP returned from the NLPFirstOrder interface
     *** are correct using finite differences (see the options_group NLPFirstDerivTester).
     *** Valid options include:
     ***    FD_DEFAULT : Perform the finite difference tests if check_results==true.
     ***    FD_TEST    : Always test, regardless of the value of check_results.
     ***    FD_NO_TEST : Never test, regardless of the value of check_results.

*    decomp_sys_testing = DST_DEFAULT; *** [default] Test if check_results==true (see above)
*    decomp_sys_testing = DST_TEST;    *** Always test
*    decomp_sys_testing = DST_NO_TEST; *** never test
     *** Determines if the range/null decomposition matrices from DecompositionSystem are
     *** tested or not (see the options_group DecompositionSystemTester).
     *** Valid options include:
     ***    FD_DEFAULT : Perform the tests if check_results==true.
     ***    FD_TEST    : Always test, regardless of the value of check_results.
     ***    FD_NO_TEST : Never test, regardless of the value of check_results.

*    decomp_sys_testing_print_level = DSPL_USE_GLOBAL;    *** [default] Use the value in journal_print_level (see above).
*    decomp_sys_testing_print_level = DSPL_LEAVE_DEFAULT; *** Leave whatever setting in already in use.
     *** This option allows the user to determine how the testing print level is determined.
     *** Valid options include:
     ***    DSLP_USE_GLOBAL    : The value of journal_print_level will be used to determine reasonable values for
     ***                         print_tests and dump_all.
     ***    DSLP_LEAVE_DEFAULT : Whatever values are currently set for DecompositionSystemTester::print_tests and
     ***                         DecompositionSystemTester::dump_all will be used (see the options_group
     ***                         DecompositionSystemTester).

}

***************************************************************
*** Options for determining if variable bounds
*** xL <= x <= xU are violated by
*** more than an acceptable tolerance.
***
options_group VariableBoundsTester {
*    warning_tol   = 1e-10; *** [default]
*    error_tol     = 1e-5; *** [default]
}

***********************************************************
*** Options for the finite difference testing of derivatives for a
*** standard NLP.
***
options_group NLPFirstDerivTester {
*    fd_testing_method = FD_COMPUTE_ALL; *** Compute all of the derivatives (O(m))
*    fd_testing_method = FD_DIRECTIONAL; *** [default] Only compute along random directions (O(1))
*    num_fd_directions = 1;   *** [fd_testing_method == DIRECTIONAL]
*    num_fd_directions = -1;  *** [fd_testing_method == DIRECTIONAL] Use single direction y=1.0
*    warning_tol   = 1e-8; *** [default]
*    warning_tol   = 0.0;  *** Show me all comparisons.
*    error_tol     = 1e-3; *** [default]
}

***************************************************************
*** Options for EvalNewPoint for a "Tailored Approach" NLP.
*** See options_group NLPDirectTester
***
options_group EvalNewPointTailoredApproach {
*    fd_deriv_testing   = FD_DEFAULT;  *** [default] Test if check_results==true (see above)
*    fd_deriv_testing   = FD_TEST;    *** Always test
*    fd_deriv_testing   = FD_NO_TEST; *** never test
}

****************************************************************
*** Options for the finite difference derivative tester for a 
*** direct sensitivity NLP.
***
options_group NLPDirectTester {
*    Gf_testing_method = FD_COMPUTE_ALL; *** Compute all of the derivatives (O(n))
*    Gf_testing_method = FD_DIRECTIONAL; *** [default] Only compute along random directions (O(1))
*    Gf_warning_tol   = 1e-10;
*    Gf_error_tol     = 1e-5;
*    Gc_testing_method = FD_COMPUTE_ALL; *** Compute all of the derivatives (O(n-m))
*    Gc_testing_method = FD_DIRECTIONAL; *** [default] Only compute along random directions (O(1))
*    Gc_warning_tol   = 1e-10;
*    Gc_error_tol     = 1e-5;
*    num_fd_directions = 1;  *** [testing_method == DIRECTIONAL]
*    dump_all = true;
*    dump_all = false; *** [default]
}

****************************************************************
*** Options for the BasisSystem tester used to validate the
*** basis of the constraints Jacobian.
***
options_group BasisSystemTester {
*    print_tests = PRINT_NONE;    *** [default]
*    print_tests = PRINT_BASIC;
*    print_tests = PRINT_MORE;
*    print_tests = PRINT_ALL;
*    dump_all = true;
*    dump_all = false;          *** [default]
*    num_random_tests = 1;      *** (+int) Number of sets of random tests to perform
*    warning_tol   = 1e-15;     *** (+dbl) Warning tolerance
*    error_tol     = 1e-12;     *** (+dbl) Error tolerance
}

****************************************************************
*** Options for the DecompositionSystem tester used to validate
*** range/null decomposition matrices (NLPFirstOrder only).
***
options_group DecompositionSystemTester {
*    print_tests = PRINT_NONE;    *** [default]
*    print_tests = PRINT_BASIC;
*    print_tests = PRINT_MORE;
*    print_tests = PRINT_ALL;
*    dump_all = true;             *** (costly)
*    dump_all = false;            *** [default]
*    num_random_tests   = 1;      *** (+int) Number of sets of random test to perform
*    mult_warning_tol   = 1e-14;  *** (+dbl) Warning tolerance for checking matrix-vector multiplication
*    mult_error_tol     = 1e-8;   *** (+dbl) Error tolerance for checking matrix-vector multiplication
*    solve_warning_tol  = 1e-14;  *** (+dbl) Warning tolerance for checking linear solves
*    solve_error_tol    = 1e-8;   *** (+dbl) Error tolerance for checking linear solves
}

*** End Moocho.opt.DecompositionSystemStateStepBuilderStd 
